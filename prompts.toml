[general_messages]
tip_correct_format = "Tip: Make sure to answer in the correct format"
tip_language = "Tip: Please make sure that you write all your answers in British English."

[general_settings]
number_of_batches = 2
questions_per_batch = 2
sequences = 3

[data_sources]
knowledge_base = """"""

[data_integration_questionnaire_generator]

system_message = "You are a data integration and gouvernance expert that can ask questions about data integration and gouvernance best practices"
# Change for different best practices
best_practices = """
1. No code/ Low Code
Capability: There are more and more tools that are emerging in market making it easier to do data integration between systems without writing any code and use out of box connectors. 
The vast array of connectors gives organization agility to integrate with systems. 
Some of the most popular connectors include snowflake and salesforce connectors besides database connectors. There are many organizations that are migrating from expensive ETL tools like Informatica Powercenter to such cloud based tools.
Enabler: Such ease in integration gives the capability makes it easy to consume data downstream for applications and apply reverse ETL.

Low code and no code tools can speed up the integration of multiple systems.

2. Integration with Data Catalog
Capability: Are data moves across multiple systems, there is an increasing need to capture the metadata such as data lineage and exported to data catalog. 
There is also increasing demand to visualize data lineage and discover underlying relationships to improve data literacy.

Enabler: Using both data catalogs and data lineage, organizations can ensure data accuracy, implement data governance, and manage business change.

Data Catalogs can help organisations to document and understand better their data, thus helping firms and companies to improved the consistency and accuracy of their data.

3. CDC (Change Data Capture)
Capability: Publish changes in data as and when changes occur. Think event instead of schedule to minimize data latency.

Enabler: Minimizing data latency often leads to providing more timely transparency/visibility to business processes and thereby taking timely business decisions.

Change data capture is ideal when you want the data to be kept up to date all the time. It is a powerful tool to keep data consistency and keep all data related systems synchronized.

4. Open Source Abstraction on Compute Engine

Since organization have compute engines such as snowflake and databaricks already in their tech stack, there is a need to either use those compute engines for ETL operations or use an abstraction later top of these compute engines. 
Tools such as dbt (data build tool) is an open-source command-line tool that helps data analysts and engineers build data models and implement data pipelines. 
Another open-source tool Apache SeaTunnel is among the top 10 Apache projects for data integration. Tools such as Pentaho and Talend also can be leveraged.

ETL tools are ideal for building data pipelines and convert data into more suitable formats for data analysis and reporting.

5. Unified Integration at scale

Capability: There is an emerging trend where there is a need to do integration with a single tool whether its bulk/batch data or real time or streaming data. 
Organizations have multiple tools for data integration where ETL us used for bulk loads, Kafka used for real time publish, Nifi for streamlining. Some of the tools are on-prem and there is trend to move these workloads and data integration capabilities on cloud. 

Enabler: Having a unified platform simplifies maintainability of the integration platform.

Unified Data Integration- Why the Whole is Greater Than the Sum
Top companies now recognize the need for a more unified integration approach that combines the right technologies and managed services to deliver a more consistent and reliable view of their data across disparate applications, ultimately driving measurable business results.
Today’s enterprise data environments can be a goldmine of insight or a quagmire of confusion depending on the company and their approach to data integration and data management. 
Many struggle to manage a complex web of cloud applications — ironically designed to alleviate the very problems they now face with data accessibility and timeliness of delivery.
"""

human_message = """Based on the best practices specified below, please generate 3 questions to help a customer on his journey to enforce these best practices.
The best practices section starts with ==== BEST PRACTICES START ==== and ends with ==== BEST PRACTICES END ====.

==== BEST PRACTICES START ====
{best_practices}
==== BEST PRACTICES END ====
"""

[data_integration_secondary_questionnaire_generator]
system_message = "You are a data integration and gouvernance expert that can ask questions about data integration and gouvernance best practices based on a pre-filled questionnaire"
human_message = """Based on the best practices specified amd on a pre-filled questionnaire by a customer that you can find below, please generate 3 questions to help the customer on his journey to enforce these best practices.
The best practices section starts with ==== BEST PRACTICES START ==== and ends with ==== BEST PRACTICES END ====.
The pre-filled questionnaire starts with ==== CUSTOMER QUESTIONNAIRE START ==== and ends with ==== CUSTOMER QUESTIONNAIRE END ====.

==== BEST PRACTICES START ====
{best_practices}
==== BEST PRACTICES END ====

==== CUSTOMER QUESTIONNAIRE START ====
{customer_questionnaire}
==== CUSTOMER QUESTIONNAIRE END ====
"""

[data_integration_advice_generator]
system_message = "You are a data integration and gouvernance expert that gives advice about data integration and gouvernance based on the output of a questionnaire and a set of data integration and gouvernance best practices"
human_message = """Based on the best practices specified amd on a pre-filled questionnaire by a customer that you can find below, please generate a list of advices to help the customer on his journey to enforce these best practices.
The best practices section starts with ==== BEST PRACTICES START ==== and ends with ==== BEST PRACTICES END ====.
The pre-filled questionnaire starts with ==== CUSTOMER QUESTIONNAIRE START ==== and ends with ==== CUSTOMER QUESTIONNAIRE END ====.

==== BEST PRACTICES START ====
{best_practices}
==== BEST PRACTICES END ====

==== CUSTOMER QUESTIONNAIRE START ====
{customer_questionnaire}
{secondary_questionnaire}
==== CUSTOMER QUESTIONNAIRE END ====
"""

[flexible_qustionnaire]
    [flexible_qustionnaire.initial]
    question = "Which area of your data ecosystem are you most concerned about?"
    system_message = "You are a data integration and gouvernance expert that can ask questions about data integration and gouvernance to help a customer with data integration and gouvernance problems"
    human_message = """Based on the best practices and knowledge base and on an answer to a question answered by a customer, \
please generate {questions_per_batch} questions that are helpful to this customer to solve data integration and gouvernance issues.
The best practices section starts with ==== BEST PRACTICES START ==== and ends with ==== BEST PRACTICES END ====.
The knowledge base section starts with ==== KNOWLEDGE BASE START ==== and ends with ==== KNOWLEDGE BASE END ====.
The question asked to the user starts with ==== QUESTION ==== and ends with ==== QUESTION END ====.
The user answer provided by the customer starts with ==== ANSWER ==== and ends with ==== ANSWER END ====.
==== BEST PRACTICES START ====
{best_practices}
==== BEST PRACTICES END ====
==== KNOWLEDGE BASE START ====
{knowledge_base}
==== KNOWLEDGE BASE END ====
==== QUESTION ====
{question}
==== QUESTION END ====
==== ANSWER ====
{answer}
==== ANSWER END ====
"""
    [flexible_qustionnaire.secondary]
    system_message = "You are a British data integration and gouvernance expert that can ask questions about data integration and gouvernance to help a customer with data integration and gouvernance problems"
    human_message = """Based on the best practices and knowledge base and answers to multiple questions answered by a customer, \
please generate {questions_per_batch} questions that are helpful to this customer to solve data integration and gouvernance issues.
The best practices section starts with ==== BEST PRACTICES START ==== and ends with ==== BEST PRACTICES END ====.
The knowledge base section starts with ==== KNOWLEDGE BASE START ==== and ends with ==== KNOWLEDGE BASE END ====.
The questions and answers section answered by the customer starts with ==== QUESTIONNAIRE ==== and ends with ==== QUESTIONNAIRE END ====.
The user answers are in the section that starts with ==== ANSWERS ==== and ends with ==== ANSWERS END ====.
==== BEST PRACTICES START ====
{best_practices}
==== BEST PRACTICES END ====
==== KNOWLEDGE BASE START ====
{knowledge_base}
==== KNOWLEDGE BASE END ====
==== QUESTIONNAIRE ====
{questions_answers}
==== QUESTIONNAIRE END ====
==== ANSWERS ====
{answers}
==== ANSWERS END ====
"""
    [flexible_qustionnaire.advisor]
    system_message = "You are a British data integration and gouvernance advisor that gives advice about data integration and gouvernance to help a customer with data integration and gouvernance problems"
    human_message = """Based on the best practices and knowledge base and answers to multiple questions answered by a customer, \
please generate a series of advices that are helpful to this customer to solve data integration and gouvernance issues.
The best practices section starts with ==== BEST PRACTICES START ==== and ends with ==== BEST PRACTICES END ====.
The knowledge base section starts with ==== KNOWLEDGE BASE START ==== and ends with ==== KNOWLEDGE BASE END ====.
The questions and answers section answered by the customer starts with ==== QUESTIONNAIRE ==== and ends with ==== QUESTIONNAIRE END ====.
==== BEST PRACTICES START ====
{best_practices}
==== BEST PRACTICES END ====
==== KNOWLEDGE BASE START ====
{knowledge_base}
==== KNOWLEDGE BASE END ====
==== QUESTIONNAIRE ====
{questions_answers}
==== QUESTIONNAIRE END ====
"""

[sentiment]
system_message = "You are an expert in terms of getting different types of sentiments from sentences."
human_message = """Given this input that starts with === INPUT START === and ends with === INPUT END ===
=== INPUT START ===
{answer}
=== INPUT END ===
can you tell me whether there is a question in it or not and whether the overall sentiment of the text indicates some sort of confusion?"""
human_message_extraction = """Given this input that starts with === INPUT START === and ends with === INPUT END ===
=== INPUT START ===
{answer}
=== INPUT END ===
can you extract question, if there is one?"""

[clarifications]
system_message = "You are an expert in terms of answering user questions like a professional data engineer."
human_message = """Given this input that starts with === INPUT START === and ends with === INPUT END ===
=== INPUT START ===
{questions}
=== INPUT END ===
can you please answer all questions you see in it?
Please be concise and limit your replies to around 30 words if possible."""
